from nltk.tokenize import sent_tokenize
text = "This is the first sentence. This is the second sentence."
sentences = sent_tokenize(text)
print(sentences)
# Output: ['This is the first sentence.', 'This is the second sentence.']